{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-805577b8aa1f>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\amita\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\amita\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./JPG-PNG-to-MNIST-NN-Format-master/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\amita\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./JPG-PNG-to-MNIST-NN-Format-master/train-labels-idx1-ubyte.gz\n",
      "Extracting ./JPG-PNG-to-MNIST-NN-Format-master/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./JPG-PNG-to-MNIST-NN-Format-master/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\amita\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\amita\\\\AppData\\\\Local\\\\Temp\\\\tmp3_x6cbk6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000205DA16D208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.9687376, step = 1\n",
      "INFO:tensorflow:global_step/sec: 29.627\n",
      "INFO:tensorflow:loss = 0.2572624, step = 101 (3.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.614\n",
      "INFO:tensorflow:loss = 0.029278507, step = 201 (3.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.9385\n",
      "INFO:tensorflow:loss = 0.010308771, step = 301 (3.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.0456\n",
      "INFO:tensorflow:loss = 0.09789112, step = 401 (3.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4489\n",
      "INFO:tensorflow:loss = 0.0014806747, step = 501 (3.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.6841\n",
      "INFO:tensorflow:loss = 0.033010714, step = 601 (3.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.5428\n",
      "INFO:tensorflow:loss = 0.001560031, step = 701 (3.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.8814\n",
      "INFO:tensorflow:loss = 0.00014666986, step = 801 (3.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.0848\n",
      "INFO:tensorflow:loss = 2.1709802e-05, step = 901 (3.323 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8.00267e-05.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-21-18:36:05\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-21-18:36:08\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9916926, global_step = 1000, loss = 0.034314644\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\\model.ckpt-1000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: amp_horz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: amp_horz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./JPG-PNG-to-MNIST-NN-Format-master/', one_hot=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 1000\n",
    "batch_size = 16\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 19 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.25 # Dropout, probability to drop a unit\n",
    "\n",
    "# Create the neural network\n",
    "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
    "    \n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        # TF Estimator input is a dict, in case of multiple inputs\n",
    "        x = x_dict['images']\n",
    "\n",
    "        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "        # Reshape to match picture format [Height x Width x Channel]\n",
    "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "\n",
    "        # Convolution Layer with 64 filters and a kernel size of 3\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "\n",
    "    return out\n",
    "\n",
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # Build the neural network\n",
    "    # Because Dropout have different behavior at training and prediction time, we\n",
    "    # need to create 2 distinct computation graphs that still share the same weights.\n",
    "    logits_train = conv_net(features, num_classes, dropout, reuse=False, is_training=True)\n",
    "    logits_test = conv_net(features, num_classes, dropout, reuse=True, is_training=False)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
    "        \n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs\n",
    "\n",
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "# Train the Model\n",
    "model.train(input_fn, steps=num_steps)\n",
    "\n",
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "model.evaluate(input_fn)\n",
    "\n",
    "# Predict single images\n",
    "n_images = 100\n",
    "# Get images from test set\n",
    "test_images = mnist.test.images[:n_images]\n",
    "# Prepare the input data\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': test_images}, shuffle=False)\n",
    "# Use the model to predict the images class\n",
    "preds = list(model.predict(input_fn))\n",
    "\n",
    "class_names =['amp_horz', 'amp_vert', 'batt_horz_neg', 'batt_horz_pos', 'batt_vert_neg', 'batt_vert_pos', 'cap_horz', 'cap_vert', 'led_horz_neg', 'led_horz_pos', 'led_vert_neg' ,'led_vert_pos', 'res_horz', 'res_vert', 'trans_horz_pos', 'trans_vert_neg', 'trans_vert_pos', 'volt_horz', 'volt_vert']\n",
    "\n",
    "# Display\n",
    "for i in range(n_images):\n",
    "    if preds[i] == 0:\n",
    "        plt.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
    "        plt.show()\n",
    "        print(\"Model prediction:\", class_names[preds[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(img):\n",
    "    import cv2\n",
    "    \n",
    "    resized_img = cv2.resize(img,(28, 28))\n",
    "\n",
    "    gray_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)        \n",
    "    \n",
    "#     inverted_img = resized_img\n",
    "    \n",
    "    inverted_img = cv2.bitwise_not(gray_img)\n",
    "    \n",
    "#     equ = cv2.equalizeHist(inverted_img)\n",
    "    \n",
    "    final_img = inverted_img\n",
    "    \n",
    "    rows,cols = final_img.shape\n",
    "    x=[]\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            x.append(final_img[i,j])\n",
    "    \n",
    "#     cv2.imshow('final_img', final_img)\n",
    "    \n",
    "    return get_class(x)\n",
    "\n",
    "    \n",
    "def get_class(x):\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': np.array([np.asarray(x, dtype=np.float32)])}, shuffle=False) # x is normal array or list of pixel values\n",
    "    # Use the model to predict the images class\n",
    "    preds = list(model.predict(input_fn))\n",
    "    \n",
    "    return class_names[preds[0]] \n",
    "    \n",
    "    # k = cv2.waitKey(0) & 0xFF\n",
    "    # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(__p):\n",
    "    # remove duplicates from __p \n",
    "    # https://stackoverflow.com/questions/21065347/remove-duplicates-in-two-dimensional-array-while-maintaining-sequence\n",
    "    \n",
    "    print(\"Number of contours:(removing duplicates)  \", len(__p))\n",
    "    \n",
    "    seen = set()\n",
    "    newlist = []\n",
    "    for item in __p:\n",
    "        t = tuple(item[:4])        \n",
    "        if t not in seen:\n",
    "            newlist.append(item)\n",
    "            seen.add(t)            \n",
    "    \n",
    "    for item in __p:\n",
    "        t = tuple(item[:4])\n",
    "        if t not in seen:\n",
    "            print(t)\n",
    "    \n",
    "    print(\"Number of contours:(removed duplicates) \", len(seen))\n",
    "    \n",
    "    return newlist\n",
    "\n",
    "def remove_giant_boxes(seen, width, height):\n",
    "    # destroy giant boxes        \n",
    "#     width_list = [] \n",
    "\n",
    "#     for p in seen:\n",
    "#         width_list.append(p[2])\n",
    "\n",
    "#     median_width = median(width_list)\n",
    "#     print(\"Median width: \", median_width)\n",
    "\n",
    "#     height_list = [] \n",
    "\n",
    "#     for p in seen:\n",
    "#         height_list.append(p[3])\n",
    "\n",
    "#     median_height = median(height_list)\n",
    "#     print(\"Median height: \", median_height)\n",
    "    \n",
    "    giants_removed=[]\n",
    "\n",
    "    for p in seen:\n",
    "        if p[2] < width/3 and p[3] < height/3:\n",
    "            giants_removed.append(p)\n",
    "            \n",
    "    return giants_removed\n",
    "\n",
    "\n",
    "def classify_circuit(filename):\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    from math import sqrt\n",
    "    from statistics import median\n",
    "    import os\n",
    "\n",
    "    name = filename\n",
    "\n",
    "    # Width of image you want to work with\n",
    "    W = 500.\n",
    "    # get original image\n",
    "    oriimg =cv2.imread('./'+name,1)\n",
    "    height, width, depth = oriimg.shape\n",
    "    # rescale to W width\n",
    "    imgScale = W/width\n",
    "    newX,newY = oriimg.shape[1]*imgScale, oriimg.shape[0]*imgScale\n",
    "    img = cv2.resize(oriimg,(int(newX),int(newY)))\n",
    "    test = cv2.resize(oriimg,(int(newX),int(newY)))\n",
    "    cv2.imshow('img', test)\n",
    "    H, W, depth = img.shape\n",
    "    print(\"Height: %d\", H)\n",
    "\n",
    "    img_hsv=cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # lower mask (0-10)\n",
    "    lower_red = np.array([0, 100, 100])\n",
    "    upper_red = np.array([10,255,255])\n",
    "    mask0 = cv2.inRange(img_hsv, lower_red, upper_red)\n",
    "\n",
    "    # upper mask (170-180)\n",
    "    lower_red = np.array([170,0,0])\n",
    "    upper_red = np.array([180,255,255])\n",
    "    mask1 = cv2.inRange(img_hsv, lower_red, upper_red)\n",
    "\n",
    "    # join my masks\n",
    "    mask = mask0+mask1\n",
    "\n",
    "    # #erode and dialate https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # set my output img to zero everywhere except my mask\n",
    "    output_img = img.copy()\n",
    "    output_img[np.where(mask==0)] = 0\n",
    "\n",
    "    # or your HSV image, which I *believe* is what you want\n",
    "    output_hsv = img_hsv.copy()\n",
    "    output_hsv[np.where(mask==0)] = 0\n",
    "\n",
    "    # # Bitwise-AND mask and cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),5)original image\n",
    "    res = cv2.bitwise_and(img,img, mask= mask)\n",
    "\n",
    "    # # contour around mask\n",
    "    i, contours, heirarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # cont_sorted contains the contours    \n",
    "    cont_sorted = sorted(contours, key=cv2.contourArea, reverse=True)[:]\n",
    "\n",
    "    print(len(cont_sorted))    \n",
    "\n",
    "\n",
    "    _p=[]\n",
    "    org = []\n",
    "    #threshhold is 10 pixels for a 500 pixel wide image. scale accordingly\n",
    "    width_thresh=W/25\n",
    "    height_thresh=W/25\n",
    "\n",
    "    # iterate through the contours\n",
    "    for idx, c in enumerate(cont_sorted):\n",
    "    #     get the bounding boxes\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "    #     only consider bounding boxes larger than thresh\n",
    "        if(w > width_thresh or h > height_thresh):                \n",
    "            _p.append([x,y,w,h])\n",
    "        #   _p now contains the bounding boxes of large contours\n",
    "            cv2.rectangle(res,(x, y),(x+w,y+h),(0,255,0),1)\n",
    "\n",
    "    org = _p\n",
    "\n",
    "    helpful = 1\n",
    "\n",
    "    while helpful == 1:\n",
    "        helpful = 0\n",
    "        print(\"Number of contours: \", len(_p))\n",
    "\n",
    "        # __p will contain the bounding boxes of merged contours i.e. one box per schematic symbol\n",
    "        __p=[]\n",
    "\n",
    "        # iterate through each bounding box\n",
    "        for idx1, p1 in enumerate(_p):\n",
    "            done =0\n",
    "        #     check all other bounding boxes for a box that's close to our box\n",
    "            for idx2, p2 in enumerate(_p):\n",
    "                x1 = p1[0]\n",
    "                x2 = p2[0]\n",
    "                y1 = p1[1]\n",
    "                y2 = p2[1]\n",
    "                w1 = p1[2]\n",
    "                w2 = p2[2]\n",
    "                h1 = p1[3]\n",
    "                h2 = p2[3]\n",
    "        #         if the bounding boxes are close together, merge them into one and put in __p\n",
    "        #      multiplier should be 1.3 or more\n",
    "                if idx1 != idx2:\n",
    "                        close = 0\n",
    "                        # if boxes are on same horizontal line\n",
    "                        if abs((y1+h1/2)-(y2+h2/2)) < height_thresh:\n",
    "                             if  (x1 < x2 and (abs(x2-(x1 + w1)) < max(w1, w2)/3)) or \\\n",
    "                                 (x2 < x1 and (abs(x1-(x2 + w2)) < max(w1, w2)/3)):\n",
    "                                close = 1\n",
    "                        # if boxes are on same vertical line\n",
    "                        if abs((x1+w1/2)-(x2+w2/2)) < width_thresh:\n",
    "                             if  (y1 < y2 and (abs(y2-(y1 + h1)) < max(h1, h2)/3)) or \\\n",
    "                                 (y2 < y1 and (abs(y1-(y2 + h2)) < max(h1, h2)/3)):\n",
    "                                close = 1\n",
    "                        \n",
    "                        if close == 1:\n",
    "                            __p.append([\n",
    "                                int(min(x1, x2)),\n",
    "                                int(min(y1, y2)),\n",
    "                                int((max(x1+w1, x2+w2)-min(x1, x2))),\n",
    "                                int((max(y1+h1, y2+h2)-min(y1, y2)))                \n",
    "                            ])\n",
    "                            done =1\n",
    "                            helpful = 1\n",
    "        #       didn't find a bounding box close to ours, so just add it to the __p list\n",
    "            if done == 0:\n",
    "                __p.append(p1)\n",
    "\n",
    "        for p in __p:\n",
    "            x = p[0]\n",
    "            y=p[1]\n",
    "            w=p[2]\n",
    "            h=p[3]\n",
    "            cv2.rectangle(res,(x, y),(x+w,y+h),(0,255,0),1)\n",
    "\n",
    "        print(\"Reduced num boxes\")\n",
    "        print(\"Number of contours: \", len(__p))\n",
    "        seen = remove_duplicates(__p)\n",
    "        print(\"Removed Duplicates\")\n",
    "        print(\"Number of contours: \", len(seen))   \n",
    "        giants_removed = remove_giant_boxes(seen, W, H)\n",
    "        print(\"Removed giant boxes\")\n",
    "        print(\"Number of contours: \", len(giants_removed))   \n",
    "        _p = giants_removed\n",
    "\n",
    "    print(\"Number of contours: \", len(_p))        \n",
    "\n",
    "    # iterate through all the bounding boxes for schematic symbols\n",
    "    for idx, p in enumerate(_p):\n",
    "        x = p[0]\n",
    "        y = p[1]\n",
    "        w = p[2]\n",
    "        h = p[3]\n",
    "\n",
    "        H = max(w, h)\n",
    "        W = H\n",
    "\n",
    "        x_center = x+w/2\n",
    "        y_center = y+h/2\n",
    "\n",
    "        X = int(x_center - W/2)\n",
    "        Y = int(y_center - H/2)\n",
    "\n",
    "        roi_alpha = 0\n",
    "\n",
    "        roi = img[int(Y-H*roi_alpha):int(Y+(1+roi_alpha)*H), int(X-W*roi_alpha):int(X+(1+roi_alpha)*W)]\n",
    "\n",
    "        symbol_class = classify(roi)\n",
    "        \n",
    "        print(symbol_class)\n",
    "        \n",
    "        symbol =cv2.imread('./symbols/'+symbol_class+'.png',1)\n",
    "        \n",
    "        resized_symbol = cv2.resize(symbol,(H*(1+2*roi_alpha),W*(1+2*roi_alpha)))\n",
    "        \n",
    "#         cv2.imshow('roi', np.hstack((roi ,resized_symbol)))\n",
    "        \n",
    "        img[int(Y-H*roi_alpha):int(Y+(1+roi_alpha)*H), int(X-W*roi_alpha):int(X+(1+roi_alpha)*W)] = resized_symbol\n",
    "        \n",
    "#         background = cv2.imread('road.jpg')\n",
    "#         overlay = cv2.imread('traffic sign.png')\n",
    "\n",
    "#         rows,cols,channels = overlay.shape\n",
    "\n",
    "#         overlay=cv2.addWeighted(background[250:250+rows, 0:0+cols],0.5,overlay,0.5,0)\n",
    "\n",
    "#         background[250:250+rows, 0:0+cols ] = overlay        \n",
    "\n",
    "#         k = cv2.waitKey(0) & 0xFF\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "        cv2.rectangle(img,(X, Y),(X+W,Y+H),(0,255,0),1)    \n",
    "\n",
    "#     cv2.imshow('mask',mask)\n",
    "    cv2.imshow('img',np.hstack((test, img)))\n",
    "#     cv2.imshow('res',res)\n",
    "\n",
    "    k = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "    if k == 27:         # wait for ESC key to exit\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height: %d 292\n",
      "6\n",
      "Number of contours:  6\n",
      "Reduced num boxes\n",
      "Number of contours:  6\n",
      "Number of contours:(removing duplicates)   6\n",
      "Number of contours:(removed duplicates)  5\n",
      "Removed Duplicates\n",
      "Number of contours:  5\n",
      "Removed giant boxes\n",
      "Number of contours:  5\n",
      "Number of contours:  5\n",
      "Reduced num boxes\n",
      "Number of contours:  5\n",
      "Number of contours:(removing duplicates)   5\n",
      "Number of contours:(removed duplicates)  5\n",
      "Removed Duplicates\n",
      "Number of contours:  5\n",
      "Removed giant boxes\n",
      "Number of contours:  5\n",
      "Number of contours:  5\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "led_horz_pos\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "trans_vert_pos\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "batt_vert_pos\n"
     ]
    }
   ],
   "source": [
    "classify_circuit(\"./test_circuits/scanned_circuit_0.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height: %d 312\n",
      "4\n",
      "Number of contours:  4\n",
      "Reduced num boxes\n",
      "Number of contours:  4\n",
      "Number of contours:(removing duplicates)   4\n",
      "Number of contours:(removed duplicates)  3\n",
      "Removed Duplicates\n",
      "Number of contours:  3\n",
      "Removed giant boxes\n",
      "Number of contours:  3\n",
      "Number of contours:  3\n",
      "Reduced num boxes\n",
      "Number of contours:  3\n",
      "Number of contours:(removing duplicates)   3\n",
      "Number of contours:(removed duplicates)  3\n",
      "Removed Duplicates\n",
      "Number of contours:  3\n",
      "Removed giant boxes\n",
      "Number of contours:  3\n",
      "Number of contours:  3\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "led_horz_pos\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "batt_vert_pos\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp3_x6cbk6\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "cap_horz\n"
     ]
    }
   ],
   "source": [
    "classify_circuit(\"./test_circuits/scanned_circuit_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height: %d 301\n",
      "5\n",
      "Number of contours:  4\n",
      "Reduced num boxes\n",
      "Number of contours:  4\n",
      "Number of contours:(removing duplicates)   4\n",
      "Number of contours:(removed duplicates)  4\n",
      "Removed Duplicates\n",
      "Number of contours:  4\n",
      "Removed giant boxes\n",
      "Number of contours:  4\n",
      "Number of contours:  4\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmpc9dqe5gp\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmpc9dqe5gp\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmpc9dqe5gp\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmpc9dqe5gp\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "led_vert_neg\n"
     ]
    }
   ],
   "source": [
    "classify_circuit(\"./test_circuits/scanned_circuit_2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height: %d 596\n",
      "4\n",
      "Number of contours:  4\n",
      "Reduced num boxes\n",
      "Number of contours:  4\n",
      "Number of contours:(removing duplicates)   4\n",
      "Number of contours:(removed duplicates)  4\n",
      "Removed Duplicates\n",
      "Number of contours:  4\n",
      "Removed giant boxes\n",
      "Number of contours:  4\n",
      "Number of contours:  4\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "trans_vert_pos\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "trans_vert_pos\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "batt_horz_pos\n"
     ]
    }
   ],
   "source": [
    "classify_circuit(\"./test_circuits/scanned_circuit_3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height: %d 243\n",
      "4\n",
      "Number of contours:  4\n",
      "Reduced num boxes\n",
      "Number of contours:  4\n",
      "Number of contours:(removing duplicates)   4\n",
      "Number of contours:(removed duplicates)  3\n",
      "Removed Duplicates\n",
      "Number of contours:  3\n",
      "Removed giant boxes\n",
      "Number of contours:  3\n",
      "Number of contours:  3\n",
      "Reduced num boxes\n",
      "Number of contours:  3\n",
      "Number of contours:(removing duplicates)   3\n",
      "Number of contours:(removed duplicates)  3\n",
      "Removed Duplicates\n",
      "Number of contours:  3\n",
      "Removed giant boxes\n",
      "Number of contours:  3\n",
      "Number of contours:  3\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "batt_horz_neg\n"
     ]
    }
   ],
   "source": [
    "classify_circuit(\"./test_circuits/scanned_circuit_4.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height: %d 647\n",
      "11\n",
      "Number of contours:  9\n",
      "Reduced num boxes\n",
      "Number of contours:  9\n",
      "Number of contours:(removing duplicates)   9\n",
      "Number of contours:(removed duplicates)  7\n",
      "Removed Duplicates\n",
      "Number of contours:  7\n",
      "Removed giant boxes\n",
      "Number of contours:  7\n",
      "Number of contours:  7\n",
      "Reduced num boxes\n",
      "Number of contours:  7\n",
      "Number of contours:(removing duplicates)   7\n",
      "Number of contours:(removed duplicates)  7\n",
      "Removed Duplicates\n",
      "Number of contours:  7\n",
      "Removed giant boxes\n",
      "Number of contours:  7\n",
      "Number of contours:  7\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "led_horz_pos\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "cap_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "trans_horz_pos\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "batt_vert_neg\n"
     ]
    }
   ],
   "source": [
    "classify_circuit(\"./test_circuits/scanned_circuit_5.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height: %d 504\n",
      "10\n",
      "Number of contours:  4\n",
      "Reduced num boxes\n",
      "Number of contours:  4\n",
      "Number of contours:(removing duplicates)   4\n",
      "Number of contours:(removed duplicates)  4\n",
      "Removed Duplicates\n",
      "Number of contours:  4\n",
      "Removed giant boxes\n",
      "Number of contours:  4\n",
      "Number of contours:  4\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "trans_vert_pos\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "trans_vert_pos\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n"
     ]
    }
   ],
   "source": [
    "classify_circuit(\"./test_circuits/circuit_3.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height: %d 293\n",
      "9\n",
      "Number of contours:  7\n",
      "Reduced num boxes\n",
      "Number of contours:  7\n",
      "Number of contours:(removing duplicates)   7\n",
      "Number of contours:(removed duplicates)  5\n",
      "Removed Duplicates\n",
      "Number of contours:  5\n",
      "Removed giant boxes\n",
      "Number of contours:  5\n",
      "Number of contours:  5\n",
      "Reduced num boxes\n",
      "Number of contours:  5\n",
      "Number of contours:(removing duplicates)   5\n",
      "Number of contours:(removed duplicates)  5\n",
      "Removed Duplicates\n",
      "Number of contours:  5\n",
      "Removed giant boxes\n",
      "Number of contours:  5\n",
      "Number of contours:  5\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "trans_vert_pos\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "trans_horz_pos\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\amita\\AppData\\Local\\Temp\\tmp4lo6rmgx\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "res_horz\n"
     ]
    }
   ],
   "source": [
    "classify_circuit(\"./test_circuits/circuit_2.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
